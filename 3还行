import argparse
import math
import os
import sys
from typing import Optional, Tuple, List
from concurrent.futures import ThreadPoolExecutor, as_completed

import cv2
import numpy as np


def ensure_dir(path: str) -> None:
    if not os.path.exists(path):
        os.makedirs(path, exist_ok=True)


def list_images(input_path: str) -> List[str]:
    exts = {".jpg", ".jpeg", ".png", ".bmp", ".JPG", ".JPEG", ".PNG", ".BMP"}
    if os.path.isdir(input_path):
        files = []
        for name in os.listdir(input_path):
            full = os.path.join(input_path, name)
            if os.path.isfile(full) and os.path.splitext(name)[1] in exts:
                files.append(full)
        files.sort()
        return files
    if os.path.isfile(input_path) and os.path.splitext(input_path)[1] in exts:
        return [input_path]
    return []


def resize_if_needed(image: np.ndarray, max_size: int) -> np.ndarray:
    if max_size is None or max_size <= 0:
        return image
    h, w = image.shape[:2]
    longest = max(h, w)
    if longest <= max_size:
        return image
    scale = max_size / float(longest)
    new_w = int(round(w * scale))
    new_h = int(round(h * scale))
    return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)


def white_balance_gray_world(image_bgr: np.ndarray) -> np.ndarray:
    image = image_bgr.astype(np.float32)
    b, g, r = cv2.split(image)
    mean_b, mean_g, mean_r = np.mean(b), np.mean(g), np.mean(r)
    mean_gray = (mean_b + mean_g + mean_r) / 3.0 + 1e-6
    gain_b = mean_gray / (mean_b + 1e-6)
    gain_g = mean_gray / (mean_g + 1e-6)
    gain_r = mean_gray / (mean_r + 1e-6)
    b *= gain_b
    g *= gain_g
    r *= gain_r
    balanced = cv2.merge([b, g, r])
    balanced = np.clip(balanced, 0, 255).astype(np.uint8)
    return balanced


def clahe_on_lab_luminance(image_bgr: np.ndarray) -> np.ndarray:
    lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l2 = clahe.apply(l)
    lab2 = cv2.merge([l2, a, b])
    return cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR)


def auto_gamma_from_brightness(image_bgr: np.ndarray) -> float:
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    mean_val = float(np.mean(gray)) / 255.0
    mean_val = max(1e-3, min(0.99, mean_val))
    gamma = math.log(0.5) / math.log(mean_val)
    gamma = max(0.5, min(2.0, gamma))
    return float(gamma)


def apply_exposure_and_gamma(image_bgr: np.ndarray, exposure: float, gamma: float) -> np.ndarray:
    img = image_bgr.astype(np.float32) / 255.0
    img *= max(0.2, min(3.0, exposure))
    img = np.power(np.clip(img, 1e-6, 1.0), 1.0 / max(0.2, min(3.0, gamma)))
    img = np.clip(img * 255.0, 0, 255).astype(np.uint8)
    return img


def denoise_color_fast(image_bgr: np.ndarray) -> np.ndarray:
    return cv2.fastNlMeansDenoisingColored(image_bgr, None, h=5, hColor=5, templateWindowSize=7, searchWindowSize=21)


def find_center(image_bgr: np.ndarray, mode: str) -> Tuple[int, int]:
    h, w = image_bgr.shape[:2]
    if mode == "center":
        return w // 2, h // 2
    if mode == "auto-brightest":
        gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (0, 0), sigmaX=15, sigmaY=15)
        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(gray)
        return int(max_loc[0]), int(max_loc[1])
    return w // 2, h // 2


def parse_center(center_str: Optional[str], image_bgr: np.ndarray) -> Tuple[int, int]:
    if center_str is None:
        return find_center(image_bgr, "center")
    s = center_str.strip().lower()
    if s == "center" or s == "centre":
        return find_center(image_bgr, "center")
    if s == "auto" or s == "auto-brightest":
        return find_center(image_bgr, "auto-brightest")
    if "," in s:
        try:
            xs, ys = s.split(",")
            h, w = image_bgr.shape[:2]
            if xs.endswith("%") and ys.endswith("%"):
                xf = max(0.0, min(100.0, float(xs[:-1]))) / 100.0
                yf = max(0.0, min(100.0, float(ys[:-1]))) / 100.0
                return int(round(xf * w)), int(round(yf * h))
            xfv = float(xs)
            yfv = float(ys)
            if 0.0 <= xfv <= 1.0 and 0.0 <= yfv <= 1.0:
                return int(round(xfv * w)), int(round(yfv * h))
            return int(round(xfv)), int(round(yfv))
        except Exception:
            pass
    return find_center(image_bgr, "center")


def simple_flashlight_effect(image_bgr: np.ndarray,
                             center_xy: Tuple[int, int],
                             center_boost: float = 1.8,
                             edge_factor: float = 0.7) -> np.ndarray:
    """
    简单地给图片中心区域提高亮度，图片周围区域降低亮度或者保持原来的暗度。

    :param image_bgr: 输入BGR图像
    :param center_xy: 光源中心坐标 (x, y)
    :param center_boost: 中心区域的最大亮度增益 (e.g., 1.8 表示提亮80%)
    :param edge_factor: 图像边缘的亮度系数 (e.g., 0.7 表示降低30%亮度)
    :return: 处理后的BGR图像
    """
    h, w = image_bgr.shape[:2]
    cx, cy = center_xy

    # 1. 创建一个从中心到最远角落的距离图
    y, x = np.ogrid[:h, :w]
    # 计算每个点到中心的距离
    dist_from_center = np.sqrt((x - cx)**2 + (y - cy)**2)
    # 找到图像对角线的一半作为最大距离参考，确保覆盖整个图像
    max_dist = np.sqrt((w/2)**2 + (h/2)**2)
    
    # 2. 将距离归一化到 [0, 1] 范围
    normalized_dist = dist_from_center / max_dist
    normalized_dist = np.clip(normalized_dist, 0., 1.)

    # 3. 创建一个权重图 (gain_map)，中心为 center_boost，边缘为 edge_factor
    # 使用平滑的过渡 (1 - dist^2)
    falloff = 1.0 - normalized_dist**2
    gain_map = edge_factor + (center_boost - edge_factor) * falloff

    # 4. 在LAB色彩空间中应用亮度调整
    lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    
    # 5. 应用亮度增益
    l_float = l.astype(np.float32)
    
    # 核心逻辑：保持暗部区域不被提亮
    # 如果原始亮度很低，并且计算出的增益大于1，则将增益限制为1（即不提亮）
    dark_threshold = 30  # L通道低于此值被认为是“暗部”
    is_dark = l_float < dark_threshold
    should_limit_gain = gain_map > 1.0
    limit_mask = is_dark & should_limit_gain
    
    final_gain_map = gain_map.copy()
    final_gain_map[limit_mask] = 1.0
    
    # 应用最终的亮度图
    l_enhanced = l_float * final_gain_map
    l_enhanced = np.clip(l_enhanced, 0, 255).astype(np.uint8)

    # 6. 合并通道并转换回BGR
    lab_enhanced = cv2.merge([l_enhanced, a, b])
    result = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    return result


def simplified_enhance_pipeline(image_bgr: np.ndarray, center: Tuple[int, int],
                                center_intensity: float, edge_intensity: float,
                                use_denoise: bool) -> np.ndarray:
    """
    简化的光照增强流水线
    """
    work = image_bgr.copy()

    # 可选降噪
    if use_denoise:
        work = denoise_color_fast(work)

    # 应用简化的手电筒效果
    work = simple_flashlight_effect(
        work, center,
        center_boost=center_intensity,
        edge_factor=edge_intensity
    )

    # 轻微锐化以保持细节
    blur = cv2.GaussianBlur(work, (0, 0), sigmaX=0.8, sigmaY=0.8)
    sharpened = cv2.addWeighted(work, 1.05, blur, -0.05, 0)

    return sharpened


def _resolve_scale_base(h: int, w: int, scale_base: str) -> float:
    scale_base = (scale_base or "diag").lower()
    if scale_base == "width":
        return float(w)
    if scale_base == "height":
        return float(h)
    if scale_base == "min":
        return float(min(h, w))
    if scale_base == "max":
        return float(max(h, w))
    return float(math.hypot(w, h))


def _resolve_length(value: float, base_len: float) -> float:
    try:
        v = float(value)
    except Exception:
        return float(value)
    if 0.0 < v <= 1.0:
        return v * base_len
    return v


def process_file(path: str, out_dir: str, center_mode: Optional[str],
                 center_intensity: float, edge_intensity: float,
                 denoise_flag: bool, max_size: int) -> Optional[str]:
    image = cv2.imread(path, cv2.IMREAD_COLOR)
    if image is None:
        print(f"[跳过] 无法读取图片: {path}")
        return None

    image = resize_if_needed(image, max_size)
    center = parse_center(center_mode, image)

    result = simplified_enhance_pipeline(
        image_bgr=image,
        center=center,
        center_intensity=float(center_intensity),
        edge_intensity=float(edge_intensity),
        use_denoise=denoise_flag,
    )

    base = os.path.basename(path)
    stem, ext = os.path.splitext(base)
    save_name = f"{stem}_flash{ext if ext else '.jpg'}"
    save_path = os.path.join(out_dir, save_name)
    ok = cv2.imwrite(save_path, result)
    if ok:
        print(f"[完成] {path} -> {save_path}")
        return save_path
    print(f"[失败] 无法写出文件: {save_path}")
    return None


def build_argparser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(
        description="给图片中心区域提高亮度，周围区域降低亮度。",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    p.add_argument("--input", required=True, help="输入单张图片或文件夹路径")
    p.add_argument("--output", required=True, help="输出目录")
    p.add_argument("--center", default="center", help="光源中心: auto-brightest | center | x,y | x%,y%")

    # 简化光照参数
    p.add_argument("--center-intensity", type=float, default=1.8, help="中心区域光照强度 (大于1.0为提亮)")
    p.add_argument("--edge-intensity", type=float, default=0.7, help="边缘区域光照强度 (小于1.0为压暗)")

    # 基础图像处理参数
    p.add_argument("--denoise", action="store_true", help="启用彩色降噪")
    p.add_argument("--max-size", type=int, default=2000, help="处理时最大边长")
    p.add_argument("--workers", type=int, default=0, help="并行工作线程数（0=自动，1=串行）")

    return p


def main(argv: Optional[List[str]] = None) -> int:
    parser = build_argparser()
    args = parser.parse_args(argv)

    files = list_images(args.input)
    if not files:
        print("未找到可处理的图片（支持 jpg/jpeg/png/bmp）。")
        return 2

    ensure_dir(args.output)

    print(f"共 {len(files)} 张图片，将输出到：{args.output}")

    def _task(pth: str):
        return process_file(
            path=pth,
            out_dir=args.output,
            center_mode=args.center,
            center_intensity=args.center_intensity,
            edge_intensity=args.edge_intensity,
            denoise_flag=args.denoise,
            max_size=args.max_size,
        )

    workers = args.workers or 0
    if workers <= 0:
        try:
            import multiprocessing
            workers = max(1, multiprocessing.cpu_count() - 1)
        except Exception:
            workers = 4

    results: List[Optional[str]] = []
    if workers == 1 or len(files) == 1:
        for f in files:
            results.append(_task(f))
    else:
        with ThreadPoolExecutor(max_workers=workers) as ex:
            future_map = {ex.submit(_task, f): f for f in files}
            for fut in as_completed(future_map):
                try:
                    results.append(fut.result())
                except Exception as e:
                    print(f"[错误] 处理失败：{future_map[fut]} -> {e}")
                    results.append(None)

    ok = sum(1 for r in results if r)
    fail = len(files) - ok
    print(f"处理完成：成功 {ok} 张，失败 {fail} 张。")

    return 0


if __name__ == "__main__":
    sys.exit(main())
