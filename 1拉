import argparse
import math
import os
import sys
from typing import Optional, Tuple, List
from concurrent.futures import ThreadPoolExecutor, as_completed

import cv2
import numpy as np


def ensure_dir(path: str) -> None:
    if not os.path.exists(path):
        os.makedirs(path, exist_ok=True)


def list_images(input_path: str) -> List[str]:
    exts = {".jpg", ".jpeg", ".png", ".bmp", ".JPG", ".JPEG", ".PNG", ".BMP"}
    if os.path.isdir(input_path):
        files = []
        for name in os.listdir(input_path):
            full = os.path.join(input_path, name)
            if os.path.isfile(full) and os.path.splitext(name)[1] in exts:
                files.append(full)
        files.sort()
        return files
    if os.path.isfile(input_path) and os.path.splitext(input_path)[1] in exts:
        return [input_path]
    return []


def resize_if_needed(image: np.ndarray, max_size: int) -> np.ndarray:
    if max_size is None or max_size <= 0:
        return image
    h, w = image.shape[:2]
    longest = max(h, w)
    if longest <= max_size:
        return image
    scale = max_size / float(longest)
    new_w = int(round(w * scale))
    new_h = int(round(h * scale))
    return cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)


def white_balance_gray_world(image_bgr: np.ndarray) -> np.ndarray:
    image = image_bgr.astype(np.float32)
    b, g, r = cv2.split(image)
    mean_b, mean_g, mean_r = np.mean(b), np.mean(g), np.mean(r)
    mean_gray = (mean_b + mean_g + mean_r) / 3.0 + 1e-6
    gain_b = mean_gray / (mean_b + 1e-6)
    gain_g = mean_gray / (mean_g + 1e-6)
    gain_r = mean_gray / (mean_r + 1e-6)
    b *= gain_b
    g *= gain_g
    r *= gain_r
    balanced = cv2.merge([b, g, r])
    balanced = np.clip(balanced, 0, 255).astype(np.uint8)
    return balanced


def clahe_on_lab_luminance(image_bgr: np.ndarray) -> np.ndarray:
    lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l2 = clahe.apply(l)
    lab2 = cv2.merge([l2, a, b])
    return cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR)


def auto_gamma_from_brightness(image_bgr: np.ndarray) -> float:
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    mean_val = float(np.mean(gray)) / 255.0
    mean_val = max(1e-3, min(0.99, mean_val))
    gamma = math.log(0.5) / math.log(mean_val)
    gamma = max(0.5, min(2.0, gamma))
    return float(gamma)


def apply_exposure_and_gamma(image_bgr: np.ndarray, exposure: float, gamma: float) -> np.ndarray:
    img = image_bgr.astype(np.float32) / 255.0
    img *= max(0.2, min(3.0, exposure))
    img = np.power(np.clip(img, 1e-6, 1.0), 1.0 / max(0.2, min(3.0, gamma)))
    img = np.clip(img * 255.0, 0, 255).astype(np.uint8)
    return img


def denoise_color_fast(image_bgr: np.ndarray) -> np.ndarray:
    return cv2.fastNlMeansDenoisingColored(image_bgr, None, h=5, hColor=5, templateWindowSize=7, searchWindowSize=21)


def find_center(image_bgr: np.ndarray, mode: str) -> Tuple[int, int]:
    h, w = image_bgr.shape[:2]
    if mode == "center":
        return w // 2, h // 2
    if mode == "auto-brightest":
        gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (0, 0), sigmaX=15, sigmaY=15)
        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(gray)
        return int(max_loc[0]), int(max_loc[1])
    return w // 2, h // 2


def parse_center(center_str: Optional[str], image_bgr: np.ndarray) -> Tuple[int, int]:
    if center_str is None:
        return find_center(image_bgr, "center")
    s = center_str.strip().lower()
    if s == "center" or s == "centre":
        return find_center(image_bgr, "center")
    if s == "auto" or s == "auto-brightest":
        return find_center(image_bgr, "auto-brightest")
    if "," in s:
        try:
            xs, ys = s.split(",")
            h, w = image_bgr.shape[:2]
            if xs.endswith("%") and ys.endswith("%"):
                xf = max(0.0, min(100.0, float(xs[:-1]))) / 100.0
                yf = max(0.0, min(100.0, float(ys[:-1]))) / 100.0
                return int(round(xf * w)), int(round(yf * h))
            xfv = float(xs)
            yfv = float(ys)
            if 0.0 <= xfv <= 1.0 and 0.0 <= yfv <= 1.0:
                return int(round(xfv * w)), int(round(yfv * h))
            return int(round(xfv)), int(round(yfv))
        except Exception:
            pass
    return find_center(image_bgr, "center")


def create_advanced_light_mask(shape: Tuple[int, int], center_xy: Tuple[int, int],
                               inner_radius: float, outer_radius: float,
                               falloff_power: float = 2.0) -> np.ndarray:
    """
    创建更自然的光照遮罩
    - inner_radius: 完全光照区域半径
    - outer_radius: 光照影响最大半径
    - falloff_power: 衰减曲线强度
    """
    h, w = shape
    cx, cy = center_xy

    # 创建坐标网格
    y, x = np.ogrid[:h, :w]

    # 计算每个像素到中心的距离
    dist = np.sqrt((x - cx) ** 2 + (y - cy) ** 2)

    # 创建光照遮罩
    mask = np.zeros_like(dist, dtype=np.float32)

    # 内圈完全光照
    inner_mask = dist <= inner_radius
    mask[inner_mask] = 1.0

    # 外圈衰减区域
    outer_region = (dist > inner_radius) & (dist <= outer_radius)
    if np.any(outer_region):
        # 归一化距离 [0, 1]
        normalized_dist = (dist[outer_region] - inner_radius) / (outer_radius - inner_radius)
        # 使用平滑的衰减曲线
        falloff = 1.0 - np.power(normalized_dist, falloff_power)
        mask[outer_region] = falloff

    return mask


def apply_physical_lighting(image_bgr: np.ndarray, center_xy: Tuple[int, int],
                            inner_radius: float, outer_radius: float,
                            center_intensity: float, edge_intensity: float,
                            falloff_power: float = 2.0) -> np.ndarray:
    """
    基于物理的光照模型
    """
    h, w = image_bgr.shape[:2]

    # 创建光照遮罩
    light_mask = create_advanced_light_mask(
        (h, w), center_xy, inner_radius, outer_radius, falloff_power
    )

    # 转换为LAB色彩空间进行亮度处理
    lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    l = l.astype(np.float32)

    # 计算每个像素的光照强度
    intensity_map = edge_intensity + (center_intensity - edge_intensity) * light_mask

    # 应用光照（使用更自然的亮度调整）
    l_enhanced = l * intensity_map
    l_enhanced = np.clip(l_enhanced, 0, 255).astype(np.uint8)

    # 合并通道
    lab_enhanced = cv2.merge([l_enhanced, a, b])
    result = cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)

    return result


def enhance_local_contrast(image_bgr: np.ndarray, center_xy: Tuple[int, int],
                           radius: float, contrast_strength: float = 0.3) -> np.ndarray:
    """
    增强中心区域的局部对比度
    """
    h, w = image_bgr.shape[:2]
    cx, cy = center_xy

    # 创建中心区域遮罩
    y, x = np.ogrid[:h, :w]
    dist = np.sqrt((x - cx) ** 2 + (y - cy) ** 2)
    center_mask = np.exp(-0.5 * (dist / (radius * 0.5)) ** 2)
    center_mask = np.clip(center_mask, 0, 1)

    # 应用局部对比度增强
    lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    l = l.astype(np.float32)

    # 中心区域对比度增强
    l_center = l / 255.0
    l_center = np.power(l_center, 1.0 - contrast_strength * center_mask)
    l_center = l_center * 255.0

    l_enhanced = l_center.astype(np.uint8)
    lab_enhanced = cv2.merge([l_enhanced, a, b])

    return cv2.cvtColor(lab_enhanced, cv2.COLOR_LAB2BGR)


def apply_vignette_effect(image_bgr: np.ndarray, center_xy: Tuple[int, int],
                          vignette_strength: float = 0.3) -> np.ndarray:
    """
    添加自然的暗角效果，增强手电筒感觉
    """
    h, w = image_bgr.shape[:2]
    cx, cy = center_xy

    # 创建暗角遮罩
    y, x = np.ogrid[:h, :w]
    dist_from_center = np.sqrt((x - cx) ** 2 + (y - cy) ** 2)
    max_dist = np.sqrt(cx ** 2 + cy ** 2)

    # 归一化距离
    normalized_dist = dist_from_center / max_dist

    # 创建暗角曲线
    vignette = 1.0 - vignette_strength * normalized_dist ** 2
    vignette = np.clip(vignette, 0.3, 1.0)

    # 应用暗角
    result = image_bgr.astype(np.float32) * vignette[..., np.newaxis]
    return np.clip(result, 0, 255).astype(np.uint8)


def advanced_light_enhance_pipeline(image_bgr: np.ndarray, center: Tuple[int, int],
                                    inner_radius: float, outer_radius: float,
                                    center_intensity: float, edge_intensity: float,
                                    exposure: float, gamma: Optional[float],
                                    use_denoise: bool, use_vignette: bool = True,
                                    falloff_power: float = 2.0) -> np.ndarray:
    """
    改进的光照增强流水线
    """
    work = image_bgr.copy()

    # Step 1: 可选降噪
    if use_denoise:
        work = denoise_color_fast(work)

    # Step 2: 白平衡
    work = white_balance_gray_world(work)

    # Step 3: 局部对比度增强
    work = clahe_on_lab_luminance(work)

    # Step 4: 曝光和伽马校正
    g = auto_gamma_from_brightness(work) if (gamma is None) else float(gamma)
    work = apply_exposure_and_gamma(work, exposure=exposure, gamma=g)

    # Step 5: 应用物理光照
    work = apply_physical_lighting(
        work, center, inner_radius, outer_radius,
        center_intensity, edge_intensity, falloff_power
    )

    # Step 6: 增强中心区域对比度
    work = enhance_local_contrast(work, center, outer_radius * 0.7)

    # Step 7: 可选暗角效果
    if use_vignette:
        work = apply_vignette_effect(work, center, vignette_strength=0.2)

    # Step 8: 最终锐化
    blur = cv2.GaussianBlur(work, (0, 0), sigmaX=0.8, sigmaY=0.8)
    sharpened = cv2.addWeighted(work, 1.1, blur, -0.1, 0)

    return sharpened


def _resolve_scale_base(h: int, w: int, scale_base: str) -> float:
    scale_base = (scale_base or "diag").lower()
    if scale_base == "width":
        return float(w)
    if scale_base == "height":
        return float(h)
    if scale_base == "min":
        return float(min(h, w))
    if scale_base == "max":
        return float(max(h, w))
    return float(math.hypot(w, h))


def _resolve_length(value: float, base_len: float) -> float:
    try:
        v = float(value)
    except Exception:
        return float(value)
    if 0.0 < v <= 1.0:
        return v * base_len
    return v


def process_file(path: str, out_dir: str, center_mode: Optional[str],
                 inner_radius: float, outer_radius: float,
                 center_intensity: float, edge_intensity: float,
                 exposure: float, gamma_opt: Optional[str], denoise_flag: bool,
                 max_size: int, use_vignette: bool, falloff_power: float,
                 scale_base: str) -> Optional[str]:
    image = cv2.imread(path, cv2.IMREAD_COLOR)
    if image is None:
        print(f"[跳过] 无法读取图片: {path}")
        return None

    image = resize_if_needed(image, max_size)
    center = parse_center(center_mode, image)

    # 解析相对尺寸参数
    h, w = image.shape[:2]
    base_len = _resolve_scale_base(h, w, scale_base)
    inner_radius_px = _resolve_length(inner_radius, base_len)
    outer_radius_px = _resolve_length(outer_radius, base_len)

    gamma: Optional[float]
    if gamma_opt is None or gamma_opt.strip().lower() == "auto":
        gamma = None
    else:
        try:
            gamma = float(gamma_opt)
        except Exception:
            gamma = None

    result = advanced_light_enhance_pipeline(
        image_bgr=image,
        center=center,
        inner_radius=float(inner_radius_px),
        outer_radius=float(outer_radius_px),
        center_intensity=float(center_intensity),
        edge_intensity=float(edge_intensity),
        exposure=float(exposure),
        gamma=gamma,
        use_denoise=denoise_flag,
        use_vignette=use_vignette,
        falloff_power=falloff_power
    )

    base = os.path.basename(path)
    stem, ext = os.path.splitext(base)
    save_name = f"{stem}_flash{ext if ext else '.jpg'}"
    save_path = os.path.join(out_dir, save_name)
    ok = cv2.imwrite(save_path, result)
    if ok:
        print(f"[完成] {path} -> {save_path}")
        return save_path
    print(f"[失败] 无法写出文件: {save_path}")
    return None


def build_argparser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(
        description="改进的低光图片增强 + 手电筒打光效果",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    p.add_argument("--input", required=True, help="输入单张图片或文件夹路径")
    p.add_argument("--output", required=True, help="输出目录")
    p.add_argument("--center", default="center", help="auto-brightest | center | x,y | x%,y%")

    # 新光照参数
    p.add_argument("--inner-radius", type=float, default=0.1, help="完全光照区域半径（相对尺寸）")
    p.add_argument("--outer-radius", type=float, default=0.4, help="光照影响最大半径（相对尺寸）")
    p.add_argument("--center-intensity", type=float, default=1.8, help="中心区域光照强度（1.0-3.0）")
    p.add_argument("--edge-intensity", type=float, default=0.7, help="边缘区域光照强度（0.3-1.2）")
    p.add_argument("--falloff-power", type=float, default=2.0, help="光照衰减曲线强度（1.0-4.0）")

    # 基础图像处理参数
    p.add_argument("--exposure", type=float, default=1.0, help="全局曝光增益")
    p.add_argument("--gamma", default="auto", help="伽马校正：auto 或数字")
    p.add_argument("--denoise", action="store_true", help="启用彩色降噪")
    p.add_argument("--no-vignette", action="store_true", help="禁用暗角效果")
    p.add_argument("--max-size", type=int, default=2000, help="处理时最大边长")
    p.add_argument("--workers", type=int, default=0, help="并行工作线程数（0=自动，1=串行）")

    # 向后兼容的旧参数（已弃用）
    p.add_argument("--intensity", type=float, help="已弃用：请使用 --center-intensity 和 --edge-intensity")
    p.add_argument("--radius", type=float, help="已弃用：请使用 --outer-radius")
    p.add_argument("--feather", type=float, help="已弃用：请使用 --falloff-power")
    p.add_argument("--flash-mode", help="已弃用：新版本只支持圆形光斑")
    p.add_argument("--beam-angle", type=float, help="已弃用：新版本只支持圆形光斑")
    p.add_argument("--beam-width", type=float, help="已弃用：请使用 --outer-radius")
    p.add_argument("--spread", type=float, help="已弃用：请使用 --falloff-power")
    p.add_argument("--atten", type=float, help="已弃用：请使用 --falloff-power")
    p.add_argument("--ambient", type=float, help="已弃用：请使用 --edge-intensity")
    p.add_argument("--luma-mode", help="已弃用：新版本使用改进的亮度控制")

    p.add_argument("--scale-base", default="diag",
                   choices=["diag", "width", "height", "min", "max"],
                   help="相对参数参考边")
    return p


def convert_legacy_params(args):
    """将旧参数转换为新参数"""
    converted = False

    # 如果使用了旧参数，给出警告并转换
    legacy_params = []
    if args.intensity is not None:
        legacy_params.append("--intensity")
        if args.center_intensity == 1.8:  # 只在默认值时覆盖
            args.center_intensity = args.intensity
            args.edge_intensity = max(0.3, args.intensity * 0.6)
    if args.radius is not None:
        legacy_params.append("--radius")
        if args.outer_radius == 0.4:
            args.outer_radius = args.radius
    if args.ambient is not None:
        legacy_params.append("--ambient")
        if args.edge_intensity == 0.7:
            args.edge_intensity = max(0.1, args.ambient)

    if legacy_params:

        converted = True

    # 忽略其他已弃用参数
    ignored_params = []
    if args.flash_mode is not None:
        ignored_params.append("--flash-mode")
    if args.beam_angle is not None:
        ignored_params.append("--beam-angle")
    if args.beam_width is not None:
        ignored_params.append("--beam-width")
    if args.spread is not None:
        ignored_params.append("--spread")
    if args.atten is not None:
        ignored_params.append("--atten")
    if args.feather is not None:
        ignored_params.append("--feather")
    if args.luma_mode is not None:
        ignored_params.append("--luma-mode")



    return converted


def main(argv: Optional[List[str]] = None) -> int:
    parser = build_argparser()
    args = parser.parse_args(argv)

    # 转换旧参数
    convert_legacy_params(args)

    files = list_images(args.input)
    if not files:
        print("未找到可处理的图片（支持 jpg/jpeg/png/bmp）。")
        return 2

    ensure_dir(args.output)

    print(f"共 {len(files)} 张图片，将输出到：{args.output}")

    def _task(pth: str):
        return process_file(
            path=pth,
            out_dir=args.output,
            center_mode=args.center,
            inner_radius=args.inner_radius,
            outer_radius=args.outer_radius,
            center_intensity=args.center_intensity,
            edge_intensity=args.edge_intensity,
            exposure=args.exposure,
            gamma_opt=args.gamma,
            denoise_flag=args.denoise,
            max_size=args.max_size,
            use_vignette=not args.no_vignette,
            falloff_power=args.falloff_power,
            scale_base=args.scale_base,
        )

    workers = args.workers or 0
    if workers <= 0:
        try:
            import multiprocessing
            workers = max(1, multiprocessing.cpu_count() - 1)
        except Exception:
            workers = 4

    results: List[Optional[str]] = []
    if workers == 1 or len(files) == 1:
        for f in files:
            results.append(_task(f))
    else:
        with ThreadPoolExecutor(max_workers=workers) as ex:
            future_map = {ex.submit(_task, f): f for f in files}
            for fut in as_completed(future_map):
                try:
                    results.append(fut.result())
                except Exception as e:
                    print(f"[错误] 处理失败：{future_map[fut]} -> {e}")
                    results.append(None)

    ok = sum(1 for r in results if r)
    fail = len(files) - ok
    print(f"处理完成：成功 {ok} 张，失败 {fail} 张。")

    return 0


if __name__ == "__main__":
    sys.exit(main())
